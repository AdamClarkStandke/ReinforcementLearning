{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aCStandke/ReinforcementLearning/blob/main/modelTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R2FNp7qQfzB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638a1c99-22c6-4f6f-eac8-1d9bbe38cc8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 170 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 44.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 93.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 80.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.7 MB/s \n",
            "\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 78.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 91.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 100.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.7 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# ignore warning messages because they are annoying lol\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "!pip install -q stable-baselines3[extra] # reinforcement learning library\n",
        "!pip install -q optuna; # hyperparameter library\n",
        "!pip install -q --upgrade importlib-metadata==4.13.0 # for backwards compatibility issue\n",
        "!pip install -q empyrical # financial calculation library\n",
        "!pip install -q yfinance # yahoo finance for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qyt-HqL-f2iV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import gym \n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import json\n",
        "import datetime as dt\n",
        "import optuna\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.utils import constant_fn\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.env_util import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_checker import VecCheckNan, check_env\n",
        "from stable_baselines3.common.callbacks import BaseCallback, CallbackList, StopTrainingOnRewardThreshold\n",
        "from stable_baselines3.common.logger import configure\n",
        "from stable_baselines3.common.callbacks import ProgressBarCallback\n",
        "from empyrical import sortino_ratio, omega_ratio\n",
        "import sqlite3\n",
        "from sqlite3 import Error\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "import collections\n",
        "import datetime\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import os\n",
        "import csv\n",
        "from csv import DictWriter\n",
        "from matplotlib import style\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8LepWiJiJqB",
        "outputId": "0503df46-809a-4be1-f4db-45b26974cf5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "'getting training and test data'\n",
        "T = 'iyt' # ticker for agent to trade in\n",
        "train_start = \"2004-01-01\" \n",
        "train_end = \"2017-12-12\"   \n",
        "test_start = \"2018-01-01\"\n",
        "test_end = \"2019-01-01\"\n",
        "train_data = yf.download(tickers=T, start=train_start, end=train_end)\n",
        "test_data =  yf.download(tickers=T, start=test_start, end=test_end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rulHF3qy1XJE"
      },
      "outputs": [],
      "source": [
        "# train_data.shape\n",
        "# test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dJiMYPDIAj3y"
      },
      "outputs": [],
      "source": [
        "'Environment Parmaters'\n",
        "# stock environment parameters\n",
        "MAX_ACCOUNT_BALANCE = 2147483647 \n",
        "MAX_NUM_SHARES = 2147483647\n",
        "MAX_SHARE_PRICE = 4294967295\n",
        "LOOKBACK_WINDOW_SIZE = 30 # trading window, default is 30 frames \n",
        "MAX_STEPS = 1e6 # num of iterations, default is 1 mil\n",
        "INITIAL_ACCOUNT_BALANCE = 10000 # starting balance and networth\n",
        "# default percentage of stock price trading agent pays broker when \n",
        "# buying/selling, default is 0.1% (i.e. very reasonable)\n",
        "DA_COMMISION = 0.1\n",
        "# validation frequency\n",
        "FEQ = MAX_STEPS/10\n",
        "# the number of concurrent environments for training  \n",
        "ENV = 3\n",
        "MODEL = T\n",
        "\n",
        "# Trading Enviornment\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, data, title, reward_func='sortinoRewardRatio', r=False, random=True, volumes=True):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "        self.data = data\n",
        "        self.random_ofs_on_reset = random\n",
        "        self.reward_func = reward_func\n",
        "        self.bars_count = LOOKBACK_WINDOW_SIZE\n",
        "        self.commission = DA_COMMISION\n",
        "        self.title = title\n",
        "        self.volumes = volumes\n",
        "        self._render_ja = r\n",
        "        \n",
        "        # Actions of the format Buy x%, Sell x%, Hold x%\n",
        "        # the action space is 3 x 10 = 30 that agent can execute\n",
        "        self.action_space = spaces.MultiDiscrete([3, 10])\n",
        "\n",
        "        # Prices contains the OHCL values for the last five prices the \n",
        "        # observation space is 6 x 10 = 60 that agent can observe\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float32)\n",
        "        \n",
        "        # setting random seed\n",
        "        self.seed()\n",
        "\n",
        "        # creating header for text output\n",
        "        if self._render_ja == True:\n",
        "          header = \"Time, Networth, Balence, SharesHeld\"\n",
        "          with open(self.title, 'a') as f:\n",
        "            f.write(header + \"\\n\")\n",
        "            f.close\n",
        "\n",
        "    def reset(self):\n",
        "      # random offset portion \n",
        "      bars = self.bars_count\n",
        "      if self.random_ofs_on_reset:\n",
        "        offset = self.np_random.choice(self.data.high.shape[0]-bars*10)+bars\n",
        "      else:\n",
        "        offset = bars\n",
        "      self._reset(offset)\n",
        "      return self._next_observation()\n",
        "\n",
        "    def _reset(self, offset):\n",
        "      self.trades = []\n",
        "      self.balance = INITIAL_ACCOUNT_BALANCE\n",
        "      self.netWorth = INITIAL_ACCOUNT_BALANCE\n",
        "      self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "      self.shares_held  = 0\n",
        "      self._offset = offset\n",
        "      # setting account history portion\n",
        "      self.account_history = np.repeat([[self.netWorth],\n",
        "                                        [self.balance],\n",
        "                                        [self.shares_held]], self.bars_count, axis=1)\n",
        "\n",
        "    # shape of observation space is 1D\n",
        "    @property\n",
        "    def shape(self):\n",
        "      if self.volumes:\n",
        "        return (8*(3*self.bars_count),)\n",
        "      else:\n",
        "        return (7*(3*self.bars_count),)\n",
        "\n",
        "    def _next_observation(self):\n",
        "      res = np.zeros(shape=self.shape, dtype=np.float32)\n",
        "      shift = 0\n",
        "      for bar_idx in range(-self.bars_count+1, 1):\n",
        "        res[shift] = self.data.open[self._offset + bar_idx]\n",
        "        shift += 1\n",
        "        res[shift] = self.data.high[self._offset + bar_idx]\n",
        "        shift += 1\n",
        "        res[shift] = self.data.low[self._offset + bar_idx]\n",
        "        shift += 1\n",
        "        res[shift] = self.data.close[self._offset + bar_idx]\n",
        "        shift += 1\n",
        "        if self.volumes:\n",
        "          res[shift] = self._prices.volume[self._offset + bar_idx]\n",
        "          shift += 1\n",
        "      for bar_idx in range(-self.bars_count, 0):\n",
        "        res[shift]=self.account_history[0][bar_idx]\n",
        "        shift+=1\n",
        "      for bar_idx in range(-self.bars_count, 0):\n",
        "        res[shift]=self.account_history[1][bar_idx]\n",
        "        shift+=1\n",
        "      for bar_idx in range(-self.bars_count, 0):\n",
        "        res[shift]=self.account_history[2][bar_idx]\n",
        "        shift+=1\n",
        "      return res\n",
        "\n",
        "       \n",
        "    def _take_action(self, action):\n",
        "      reward = 0\n",
        "      current_price = self._cur_close()\n",
        "      action_type = action[0]\n",
        "      amount = action[1]/10\n",
        "\n",
        "      shares_bought = 0\n",
        "      shares_sold = 0\n",
        "      additional_cost = 0\n",
        "      sales = 0\n",
        "\n",
        "      if action_type < 1 and int(self.balance) > 0 and action[1] > 0:\n",
        "        # Buy amount % of balance in shares\n",
        "        total_possible = self.balance / (current_price * (1+self.commission))\n",
        "        shares_bought = total_possible * amount\n",
        "        additional_cost = shares_bought * current_price * (1+self.commission)\n",
        "        self.balance -= additional_cost\n",
        "        self.shares_held += shares_bought\n",
        "        # trading history\n",
        "        if shares_bought > 0:\n",
        "          self.trades.append({'step': self._offset, 'shares': shares_bought, \n",
        "                              'total': additional_cost, 'type': \"buy\"})\n",
        "      if action_type < 2 and int(self.shares_held) > 0 and action[1] > 0:\n",
        "        # Sell amount % of shares held\n",
        "        shares_sold = self.shares_held * amount  \n",
        "        sales = shares_sold * current_price * (1 - self.commission)\n",
        "        self.balance += sales\n",
        "        self.shares_held -= shares_sold\n",
        "        # trading history\n",
        "        if shares_sold > 0:\n",
        "          self.trades.append({'step': self._offset, 'shares': -shares_sold, \n",
        "                              'total': shares_sold * current_price, 'type': \"sell\"})\n",
        "\n",
        "      \n",
        "      self.netWorth = self.balance + self.shares_held * current_price\n",
        "        \n",
        "\n",
        "      # updating account history\n",
        "      self.account_history = np.append(self.account_history, [[self.netWorth],\n",
        "                                                              [self.balance],\n",
        "                                                              [self.shares_held]],axis=1)\n",
        "      \n",
        "      # reward Calculations based off networth history\n",
        "      returns = self.account_history[0][-self.bars_count:]\n",
        "      # calcualtion for ratio based rewards\n",
        "      r = np.diff(returns)\n",
        "      # sortinoRewardRatio\n",
        "      if self.reward_func == 'sortinoRewardRatio':\n",
        "        ratio = sortino_ratio(r, period=\"daily\") # default period daily\n",
        "        reward= ratio \n",
        "        if self.netWorth > self.max_net_worth:\n",
        "          self.max_net_worth = self.netWorth\n",
        "          reward *= 100\n",
        "      # Omega Ratio\n",
        "      elif self.reward_func == 'omegaRewardRatio':\n",
        "        ratio = omega_ratio(r) \n",
        "        reward= ratio\n",
        "        if self.netWorth > self.max_net_worth:\n",
        "          self.max_net_worth = self.netWorth\n",
        "          reward *= 100\n",
        "      # None\n",
        "      else:\n",
        "        reward = sum(r)*10\n",
        "        if self.netWorth > self.max_net_worth:\n",
        "          self.max_net_worth = self.netWorth\n",
        "          reward *= 100\n",
        "      return reward if abs(reward) != np.inf and not np.isnan(reward) else 0\n",
        "\n",
        "      \n",
        "    def _cur_close(self):\n",
        "      \"\"\"\n",
        "      Calculate real close price for the current bar\n",
        "      \"\"\"\n",
        "      return self.data.real_close[self._offset]\n",
        "\n",
        "    def step(self, action):\n",
        "      # Execute one time step within the environment\n",
        "      reward = self._take_action(action)\n",
        "      self._offset += 1\n",
        "      if self._offset >= self.data.close.shape[0]-1 or int(self.netWorth)<1 or int(self.netWorth)>=MAX_ACCOUNT_BALANCE:\n",
        "        done=True\n",
        "      else:\n",
        "        done=False\n",
        "      obs = self._next_observation()\n",
        "      info = {\"Net Worth\":self.netWorth, \"reward\": reward, 'Balance': self.balance}\n",
        "      return obs, reward, done, info\n",
        "\n",
        "    def _render_to_file(self):\n",
        "      with open(self.title, 'a') as f:\n",
        "        f.write(f'{self.data.date[self._offset]},{self.netWorth},{self.balance},{self.shares_held}\\n')\n",
        "        f.close()\n",
        " \n",
        "    def render(self, mode='file', title=\"Agent's Trading Screen\", **kwargs):\n",
        "      # Render the environment to the screen\n",
        "      if mode == 'file':\n",
        "        if self._render_ja == True:\n",
        "          self._render_to_file()\n",
        "\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "      self.np_random, seed1 = seeding.np_random(seed)\n",
        "      seed2 = seeding.hash_seed(seed1+1) % 2**33\n",
        "      return [seed1, seed2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "szUR1sYHHEVl"
      },
      "outputs": [],
      "source": [
        "# create a log-differenced series (i.e. lag one) to create stationary input\n",
        "# as detailed by Jason in his post \n",
        "# https://machinelearningmastery.com/remove-trends-seasonality-difference-transform-python/\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = np.log(dataset[i]) - np.log(dataset[i - interval])\n",
        "\t\tdiff.append(value)\n",
        "\treturn diff\n",
        "\n",
        "\n",
        "# training data\n",
        "train_data['Date']=train_data.index\n",
        "data=train_data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "\n",
        "# # making OHLC data stationary  \n",
        "# o = np.array(difference(data['Open'], 1))\n",
        "# rh = np.array(difference(data['High'], 1))\n",
        "# rl = np.array(difference(data['Low'], 1))\n",
        "# rc = np.array(difference(data['Close'], 1))\n",
        "\n",
        "# regular price data\n",
        "o = data['Open']\n",
        "rh = data['High']\n",
        "rl = data['Low']\n",
        "rc = data['Close']\n",
        "# volumne data\n",
        "vol = data['Volume'].values\n",
        "# year data of year-month-day form\n",
        "dt = data['Date'].array\n",
        "\n",
        "\n",
        "Train_Data = collections.namedtuple('Data', field_names=['date','high', 'low', 'close', 'open', 'volume', 'real_open',  'real_close', 'real_high', 'real_low', 'real_vol'])\n",
        "train = Train_Data(date=dt,high=rh, low=rl, close=rc, open=o, volume=vol, real_open=data['Open'].values, real_close=data['Close'].values, real_high=data['High'].values, real_low=data['Low'].values, real_vol=data['Volume'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1TdubrWOfamD"
      },
      "outputs": [],
      "source": [
        "# Testing data\n",
        "test_data['Date']=test_data.index\n",
        "data_two=test_data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "\n",
        "# # making OHLC data stationary  \n",
        "# diff_o = np.array(difference(data_two['Open'], 1))\n",
        "# diff_h = np.array(difference(data_two['High'], 1))\n",
        "# diff_l = np.array(difference(data_two['Low'], 1))\n",
        "# diff_c = np.array(difference(data_two['Close'], 1))\n",
        "\n",
        "# regular price data\n",
        "diff_o = data_two['Open']\n",
        "diff_h = data_two['High']\n",
        "diff_l = data_two['Low']\n",
        "diff_c = data_two['Close']\n",
        "# volumne data\n",
        "vols = data_two['Volume'].values\n",
        "# year data of year-month-day form\n",
        "date = data_two['Date'].array\n",
        "\n",
        "Test_Data = collections.namedtuple('Data', field_names=['date','high', 'low', 'close', 'open', 'volume', 'real_open', 'real_close', 'real_high', 'real_low', 'real_vol'])\n",
        "test = Test_Data(date=date,high=diff_h, low=diff_l, close=diff_c, open=diff_o, volume=vols, real_open=data_two['Open'].values, real_close=data_two['Close'].values, real_high=data_two['High'].values, real_low=data_two['Low'].values, real_vol=data_two['Volume'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1hEB-iRM4GLz"
      },
      "outputs": [],
      "source": [
        "def evaluate_policy(model,env,n_eval_episodes=1,deterministic=False):\n",
        "    episode_rewards, networths, episode_balances = [], [], []\n",
        "    for i in range(n_eval_episodes):\n",
        "        done, state = False, None\n",
        "        episode_reward = 0.0\n",
        "        episode_length = 0\n",
        "        episode_balance = 0\n",
        "        networth = 0\n",
        "        obs = env.reset()\n",
        "        while not done:\n",
        "            action, state = model.predict(obs, state=state, deterministic=deterministic)\n",
        "            new_obs, reward, done, _info = env.step(action)\n",
        "            obs = new_obs\n",
        "            episode_reward += reward\n",
        "            episode_balance += _info[0]['Balance']\n",
        "            networth += _info[0]['Net Worth']\n",
        "        episode_rewards.append(episode_reward)\n",
        "        episode_balances.append(episode_balance)\n",
        "        networths.append(networth)\n",
        "    mean_reward = np.mean(episode_rewards)\n",
        "    mean_networth = np.mean(networths)\n",
        "    mean_balance = np.mean(episode_balances)\n",
        "    return mean_reward, _info[0]['Net Worth'], _info[0]['Balance']\n",
        "\n",
        "\n",
        "class TensorboardCallback(BaseCallback):\n",
        "    def __init__(self, env, eval,  verbose=1):\n",
        "        super(TensorboardCallback, self).__init__(verbose)\n",
        "        self.eval= eval\n",
        "        self.env = env\n",
        "\n",
        "    def _on_step(self):\n",
        "      if (self.num_timesteps % self.eval == 0):\n",
        "        m, net, bal = evaluate_policy(self.model, self.env)\n",
        "        self.logger.record('Last Networth Value', net)\n",
        "        self.logger.record('Last Balance Value', bal)\n",
        "      return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cAJYlkEqIwcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "3168aa9dd9144ce986669ab95dbcd31e",
            "b79558c9ecb64d63b3c46bb4c8daa4be"
          ]
        },
        "outputId": "fd5fed58-941d-42ba-e915-42f13f226133"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3168aa9dd9144ce986669ab95dbcd31e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=3000, episode_reward=-1553.82 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=3000, episode_reward=-1553.82 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 220.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 220.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=6000, episode_reward=-1551.18 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=6000, episode_reward=-1551.18 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 220.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 220.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=9000, episode_reward=-1491.38 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=9000, episode_reward=-1491.38 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 220.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 220.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Eval num_timesteps=12000, episode_reward=-1410.49 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Eval num_timesteps=12000, episode_reward=-1410.49 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Episode length: 220.00 +/- 0.00\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode length: 220.00 +/- 0.00\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New best mean reward!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New best mean reward!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fb519f8b250>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# create evaluation env \n",
        "eval_env = DummyVecEnv([lambda: StockTradingEnv(test, f'{MODEL}.txt', random=False, volumes=False)])\n",
        "# create training envs (can be 1 or determined by ENV variable, defualt is 3)\n",
        "envs =  DummyVecEnv([lambda: StockTradingEnv(train, f'{MODEL}.txt', random=True, volumes=False) for _ in range(0,ENV)])\n",
        "\n",
        "# callback list for tracking purposes \n",
        "eval_callback = EvalCallback(eval_env, best_model_save_path=f'{MODEL}',\n",
        "                             log_path=f'{MODEL}_log', eval_freq=FEQ,\n",
        "                             deterministic=False, render=False, n_eval_episodes=1)\n",
        "callback = CallbackList([TensorboardCallback(eval_env, FEQ), eval_callback])\n",
        "\n",
        "# optional additional keyword parameters to pass to PPO agent \n",
        "policy_kwargs = dict(net_arch=[128, dict(vf=[64, 32], pi=[64, 32])])\n",
        "# Initializing PPO agent\n",
        "model = PPO('MlpPolicy', envs,  verbose=0, tensorboard_log=f\"/content/tensorboard\", policy_kwargs=policy_kwargs)\n",
        "\n",
        "# check to make sure no erros in the env, such as observation space errors or nans\n",
        "check_env(StockTradingEnv(train, f'{MODEL}.txt', random=True, volumes=False))\n",
        "VecCheckNan(envs, raise_exception=True, check_inf=True)\n",
        "\n",
        "# Agent training\n",
        "model.learn(total_timesteps=MAX_STEPS, callback=callback, progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvrZ0gN0khs0"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/tensorboard/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXu6Nsgjkv95"
      },
      "outputs": [],
      "source": [
        "model = PPO.load(f'{MODEL}/best_model.zip')\n",
        "env = StockTradingEnv(test, f'{MODEL}.txt', r=True, random=False, volumes=False)\n",
        "obs = env.reset()\n",
        "for i in range(len(test.date)):\n",
        "  action, _states = model.predict(obs, deterministic=False)\n",
        "  obs, rewards, done, info = env.step(action)\n",
        "  env.render()\n",
        "  if done:\n",
        "    break\n",
        "df = pd.read_csv(f'{MODEL}.txt')\n",
        "df[' SharesHeld']=df[' SharesHeld']*100\n",
        "x = np.arange(data_two['Close'].size)\n",
        "fit = np.polyfit(x, data_two['Close'], deg=2)\n",
        "fit_function = np.poly1d(fit)\n",
        "y = fit_function(x)\n",
        "\n",
        "for i, row in enumerate(data_two[\"Date\"]):\n",
        "  p = re.compile(\" 00:00:00\")\n",
        "  datetime = p.split(str(data_two[\"Date\"][i]))[0]\n",
        "  data_two.iloc[i, 0] = datetime\n",
        "\n",
        "for i, row in enumerate(df[\"Time\"]):\n",
        "  p = re.compile(\" 00:00:00\")\n",
        "  datetime = p.split(str(df[\"Time\"][i]))[0]\n",
        "  df.iloc[i, 0] = datetime\n",
        "\n",
        "# drawing the interactive figure\n",
        "fig = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    shared_xaxes=True, \n",
        "    vertical_spacing = 0.03, \n",
        "    specs =[[{\"type\": \"candlestick\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}]]\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x = df[\"Time\"],\n",
        "        y = df[' Networth'],\n",
        "        mode = \"lines\", \n",
        "        name = \"NetWorth\"\n",
        "    ), \n",
        "    row=3, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x = df[\"Time\"],\n",
        "        y = df[' Balence'],\n",
        "        mode = \"lines\", \n",
        "        name = \"Balance\"\n",
        "    ), \n",
        "    row=3, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x = df[\"Time\"],\n",
        "        y = df[' SharesHeld'],\n",
        "        mode = \"lines\", \n",
        "        name = \"SharesHeld\"\n",
        "    ), \n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x = data_two[\"Date\"],\n",
        "        y = data_two['Close'],\n",
        "        mode = \"lines\", \n",
        "        name = \"Real Close\"\n",
        "    ), \n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x = data_two[\"Date\"],\n",
        "        y = y,\n",
        "        mode = \"lines\", \n",
        "        name = \"Tend Line\"\n",
        "    ), \n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Candlestick(\n",
        "        x = data_two[\"Date\"],\n",
        "        open = data_two[\"Open\"],\n",
        "        high = data_two[\"High\"], \n",
        "        low = data_two[\"Low\"], \n",
        "        close = data_two[\"Close\"]\n",
        "    ), \n",
        "    row=1, col=1\n",
        ")\n",
        "fig.update_layout(xaxis_rangeslider_visible=False)\n",
        "fig.show()\n",
        "# # create numpy array to fit regression line\n",
        "# x = np.arange(data_two['Close'].size)\n",
        "# fit = np.polyfit(x, data_two['Close'], deg=2)\n",
        "# fit_function = np.poly1d(fit)\n",
        "# y = fit_function(data_two['Close'].index)\n",
        "# plt.style.use('seaborn-darkgrid')\n",
        "# fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
        "# data_two[\"Date\"] = pd.to_datetime(data_two['Date'], format='%Y-%m-%d')\n",
        "# data_two.plot(ax=axes[0], x='Date', y='Close')\n",
        "# axes[0].set_ylabel('Price', fontsize=20)\n",
        "# #Linear regression plot\n",
        "# sns.lineplot(ax=axes[0], x=data_two['Close'].index ,y=fit_function(x))\n",
        "# df[\"Time\"] = pd.to_datetime(df['Time'], format='%Y-%m-%d')\n",
        "# df.plot(ax=axes[1], x=\"Time\", y=[' Networth', ' Balence', ' SharesHeld'])\n",
        "# axes[1].set_ylabel('Account', fontsize=20)\n",
        "# fig.set_figwidth(15)\n",
        "# fig.set_figheight(15)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/*.txt"
      ],
      "metadata": {
        "id": "oHTde474nG6_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "14PTov59y5BsmHQNkGSVeWkMeD2L6FVWz",
      "authorship_tag": "ABX9TyMW+gpYrVnmH/dz7QyoTov2",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3168aa9dd9144ce986669ab95dbcd31e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_b79558c9ecb64d63b3c46bb4c8daa4be",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12,219/10,000 \u001b[0m [ \u001b[33m0:00:27\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m470 it/s\u001b[0m ]\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">12,219/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:27</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">470 it/s</span> ]\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "b79558c9ecb64d63b3c46bb4c8daa4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
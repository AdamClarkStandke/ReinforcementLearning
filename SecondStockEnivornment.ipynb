{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondStockEnivornment",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1BnRqmo4sw9dhUsiP_WO4HGPM9M7Cryi7",
      "authorship_tag": "ABX9TyMzmWX83tDSc4ksx4ATn7mQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aCStandke/ReinforcementLearning/blob/main/SecondStockEnivornment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Stock Trading Environment\n",
        "\n",
        "\n",
        "> This second stock environment is based on Adam King's article as found here:[Create custom gym environments from scratch â€” A stock market example](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e). Similar to the first stock trading environment based on Maxim Lapan's implementation as found in chapter eight of his book [Deep Reinforcement Learning Hands-On: Apply modern RL methods to practical problems of chatbots, robotics, discrete optimization, web automation, and more, 2nd Edition](https://www.amazon.com/Deep-Reinforcement-Learning-Hands-optimization/dp/1838826998), the agent is trading in the environment of the [SPY ETF](https://www.etf.com/SPY?L=1) except in this trading environment the agent is taking continuous actions, rather than discrete actions and is tasked with managing a [trading account](https://www.investopedia.com/terms/t/tradingaccount.asp#:~:text=A%20trading%20account%20is%20an,margin%20requirements%20set%20by%20FINRA.).  In the first trading environment, the agent's reward is based on relative price movement, however in this trading environment the agent's reward is based on managing its trading account. As Adam King details the agent can take two continous actions; namely, either buying or selling the SPY and by what percentage. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3TBwoqXizywK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "OHO1Q4dS9tF0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT_p1bNSDnJ_",
        "outputId": "06faf438-c51c-4052-923e-3fb4137779b5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.12.1+cu113)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (1.21.6)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.21.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (4.6.0.66)\n",
            "Requirement already satisfied: protobuf~=3.19.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (3.19.4)\n",
            "Requirement already satisfied: ale-py==0.7.4 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.7.4)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (0.4.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (5.4.8)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (7.1.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]) (2.8.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from ale-py==0.7.4->stable-baselines3[extra]) (4.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.64.0)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->ale-py==0.7.4->stable-baselines3[extra]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.10.0->ale-py==0.7.4->stable-baselines3[extra]) (4.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.47.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3[extra]) (2022.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "AoLhA3_b_XeK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import json\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import datetime as dt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import collections\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock Environment Parameters\n",
        "MAX_ACCOUNT_BALANCE = 2147483647\n",
        "MAX_NUM_SHARES = 2147483647\n",
        "MAX_STEPS = 20000\n",
        "TRADING_DAYS = 5\n",
        "DEFAULT_COMMISSION_PERC = 0.01\n",
        "INITIAL_ACCOUNT_BALANCE = 10000"
      ],
      "metadata": {
        "id": "OB9FxIN_AQC4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock/ETF Trading Enviornment\n",
        "class StockTradingEnv(gym.Env):\n",
        "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, data, random_ofs_on_reset=True, commission_prec=DEFAULT_COMMISSION_PERC):\n",
        "        super(StockTradingEnv, self).__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.random_ofs_on_reset = random_ofs_on_reset\n",
        "        self.bars_count = TRADING_DAYS\n",
        "        self.commission_perc = commission_prec\n",
        "        self.buy_queue = []\n",
        "        self.sell_queue = []\n",
        "\n",
        "        # Actions of the format Buy x%, Sell x%, Hold, etc.\n",
        "        self.action_space = spaces.Box(\n",
        "            low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float32)\n",
        "\n",
        "        # Prices contains the OHCL values for the last five prices\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=1, shape=self.shape)\n",
        "        \n",
        "        self.random_ofs_on_reset = random_ofs_on_reset\n",
        "        self.seed()\n",
        "\n",
        "    def reset(self):\n",
        "      bars = self.bars_count\n",
        "      if self.random_ofs_on_reset:\n",
        "        offset = self.np_random.choice(self.data.high.shape[0]-bars*10)+bars\n",
        "      else:\n",
        "        offset = bars\n",
        "      self._reset(offset)\n",
        "      return self._next_observation()  \n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "      return (4*self.bars_count+4, )\n",
        "\n",
        "    def _next_observation(self):\n",
        "        # Get the stock data points for the last 5 days and scale to between 0-1\n",
        "        res = np.ndarray(shape=self.shape, dtype=np.float32)\n",
        "        shift = 0\n",
        "        for bar_idx in range(-self.bars_count+1, 1):\n",
        "          res[shift] = self.data.high[self._offset + bar_idx]\n",
        "          shift += 1\n",
        "          res[shift] = self.data.low[self._offset + bar_idx]\n",
        "          shift += 1\n",
        "          res[shift] = self.data.close[self._offset + bar_idx]\n",
        "          shift += 1\n",
        "          res[shift] = self.data.volume[self._offset + bar_idx]\n",
        "          shift += 1\n",
        "\n",
        "        # Append additional data and scale each value to between 0-1\n",
        "        res[shift] = self.balance / MAX_ACCOUNT_BALANCE\n",
        "        shift += 1\n",
        "        res[shift] = self.shares_held / MAX_NUM_SHARES\n",
        "        shift += 1\n",
        "        res[shift] = self.total_shares_sold / MAX_NUM_SHARES\n",
        "        shift += 1\n",
        "        res[shift] = self.total_shares_bought/MAX_NUM_SHARES\n",
        "      \n",
        "        return res\n",
        "\n",
        "    def _take_action(self, action):\n",
        "\n",
        "        reward = 0.0\n",
        "        current_price = self._cur_close()\n",
        "        action_type = action[0]\n",
        "        amount = action[1]\n",
        "\n",
        "        if action_type < 1:\n",
        "            total_possible = int(self.balance / current_price)\n",
        "            total_possible = abs(total_possible)\n",
        "            shares_bought = int(total_possible * amount)\n",
        "            additional_cost = (shares_bought * current_price) + (shares_bought * current_price)*self.commission_perc\n",
        "\n",
        "            # balance calculation \n",
        "            self.balance -= additional_cost\n",
        "         \n",
        "\n",
        "            self.shares_held += shares_bought\n",
        "            self.total_shares_bought += shares_bought\n",
        "            \n",
        "\n",
        "        elif action_type < 2:\n",
        "            shares_sold = int(self.shares_held * amount)\n",
        "            \n",
        "            # balance calculation \n",
        "            self.balance += (shares_sold * current_price) - (shares_sold * current_price)*self.commission_perc\n",
        "           \n",
        "\n",
        "            self.shares_held -= shares_sold\n",
        "            self.total_shares_sold += shares_sold\n",
        "\n",
        "\n",
        "        \n",
        "        self.net_worth = self.balance + self.shares_held * current_price\n",
        "        reward += self.balance\n",
        "\n",
        "\n",
        "        if self.net_worth > self.max_net_worth:\n",
        "          self.max_net_worth = self.net_worth\n",
        "\n",
        "        \n",
        "        self._offset += 1\n",
        "\n",
        "        return reward \n",
        "\n",
        "    def _cur_close(self):\n",
        "      \"\"\"\n",
        "      Calculate real close price for the current bar\n",
        "      \"\"\"\n",
        "      open = self.data.open[self._offset]\n",
        "      rel_close = self.data.close[self._offset]\n",
        "      return open * (1.0 + rel_close)\n",
        "\n",
        "    def step(self, action):\n",
        "        # Execute one time step within the environment\n",
        "        reward = self._take_action(action)\n",
        "\n",
        "        \n",
        "        if self.balance <= 0 or self.net_worth >= MAX_ACCOUNT_BALANCE or self._offset >= self.data.close.shape[0]-1:\n",
        "          done=True\n",
        "        else:\n",
        "          done=False\n",
        "\n",
        "\n",
        "        obs = self._next_observation()\n",
        "\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "    def _reset(self, offset):\n",
        "        # Reset the state of the environment to an initial state\n",
        "        self.balance = INITIAL_ACCOUNT_BALANCE\n",
        "        self.net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
        "        self.shares_held = 0\n",
        "        self.total_shares_sold = 0\n",
        "        self.total_sales_value = 0\n",
        "        self.total_shares_bought = 0\n",
        "        self._offset = offset\n",
        "\n",
        "\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "      # Render the environment to the screen\n",
        "      print(self.balance)\n",
        "\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "      self.np_random, seed1 = seeding.np_random(seed)\n",
        "      seed2 = seeding.hash_seed(seed1+1) % 2**33\n",
        "      return [seed1, seed2]\n"
      ],
      "metadata": {
        "id": "dJiMYPDIAj3y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/StockMarketData/archive/Data/ETFs/spy.us.txt')\n",
        "df = df.sort_values('Date')\n",
        "data=df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "\n",
        "# year data of year-month-day form\n",
        "dt = data['Date'].array\n",
        "# calculating relative prices \n",
        "rh = (data['High'].values-data['Open'].values)/data['Open'].values\n",
        "rl = (data['Low'].values-data['Open'].values)/data['Open'].values\n",
        "rc = (data['Close'].values-data['Open'].values)/data['Open'].values\n",
        "o = data['Open'].values\n",
        "# volumne data\n",
        "vol = data['Volume'].values\n",
        "\n",
        "Data = collections.namedtuple('Data', field_names=['date','high', 'low', 'close', 'open', 'volume'])\n",
        "data=Data(date=dt,high=rh, low=rl, close=rc, open=o, volume=vol)"
      ],
      "metadata": {
        "id": "szUR1sYHHEVl"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The algorithms require a vectorized environment to run\n",
        "env = StockTradingEnv(data)\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAJYlkEqIwcK",
        "outputId": "91486715-eadf-4591-c07d-84084bb3be86"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.learn(total_timesteps=MAX_STEPS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6sMSFIuhLzx",
        "outputId": "ecadda00-3afb-49d4-f24e-e12e217f0adf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 36.3     |\n",
            "|    ep_rew_mean     | 8.57e+04 |\n",
            "| time/              |          |\n",
            "|    fps             | 806      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 2        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 43.1         |\n",
            "|    ep_rew_mean          | 9.2e+04      |\n",
            "| time/                   |              |\n",
            "|    fps                  | 604          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036704834 |\n",
            "|    clip_fraction        | 0.00532      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.34e+08     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00609     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 8.31e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 50.2         |\n",
            "|    ep_rew_mean          | 1.05e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 546          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018476126 |\n",
            "|    clip_fraction        | 0.000391     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13e+08     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 7.74e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 53           |\n",
            "|    ep_rew_mean          | 1.12e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 532          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011274498 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.16e+08     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 9.55e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 55.8         |\n",
            "|    ep_rew_mean          | 1.22e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 524          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018588635 |\n",
            "|    clip_fraction        | 0.000342     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.34e+08     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00341     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1e+09        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 54.7         |\n",
            "|    ep_rew_mean          | 1.32e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 508          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017785097 |\n",
            "|    clip_fraction        | 0.000391     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.52e+08     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00365     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.25e+09     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 49.7         |\n",
            "|    ep_rew_mean          | 1.44e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 507          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012686779 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.05e+08     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.36e+09     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 52.6         |\n",
            "|    ep_rew_mean          | 1.58e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 506          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009800092 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.85e+08     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.9e+09      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 48.5         |\n",
            "|    ep_rew_mean          | 1.53e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 505          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011302038 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.63e+08     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.83e+09     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 58.2         |\n",
            "|    ep_rew_mean          | 1.7e+05      |\n",
            "| time/                   |              |\n",
            "|    fps                  | 505          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013706022 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.63e+08     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00332     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.94e+09     |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7f3739f54e50>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs = env.reset()\n",
        "for i in range(30):\n",
        "  action, _states = model.predict(obs)\n",
        "  obs, rewards, done, info = env.step(action)\n",
        "  env.render()"
      ],
      "metadata": {
        "id": "dpOBmCDTKyEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4736e01e-43f3-4358-f9d6-986a9e6a9f12"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6998.1487\n",
            "6998.1487\n",
            "6998.1487\n",
            "6998.1487\n",
            "5126.8611\n",
            "5126.8611\n",
            "4410.9226\n",
            "1967.1164999999996\n",
            "1967.1164999999996\n",
            "1967.1164999999996\n",
            "1967.1164999999996\n",
            "1967.1164999999996\n",
            "1967.1164999999996\n",
            "2828.5352999999996\n",
            "2828.5352999999996\n",
            "2828.5352999999996\n",
            "4791.9429\n",
            "4791.9429\n",
            "4791.9429\n",
            "3063.3885\n",
            "3063.3885\n",
            "3063.3885\n",
            "3063.3885\n",
            "4923.4896\n",
            "4923.4896\n",
            "4923.4896\n",
            "4923.4896\n",
            "61.30919999999969\n",
            "61.30919999999969\n",
            "61.30919999999969\n"
          ]
        }
      ]
    }
  ]
}